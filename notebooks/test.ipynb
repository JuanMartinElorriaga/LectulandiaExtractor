{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from queue import Queue\n",
    "from threading import Thread\n",
    "import werkzeug\n",
    "werkzeug.cached_property = werkzeug.utils.cached_property\n",
    "from robobrowser import RoboBrowser\n",
    "import re\n",
    "import time\n",
    "from requests import Session\n",
    "import os\n",
    "from unidecode import unidecode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Downloader():\n",
    "    def __init__(self, proxy=None, worker_num=0):\n",
    "        self.worker_num = worker_num\n",
    "        session         = Session()\n",
    "        if proxy is not None:\n",
    "            session.proxies = {'http': proxy, 'https': proxy}\n",
    "        self.browser = RoboBrowser(history=True, parser='html.parser', session=session)\n",
    "\n",
    "\n",
    "    def get_author_url(self, author):\n",
    "        ''' Get author url from input given '''\n",
    "        author_name = author.replace(\" \", \"-\").lower()\n",
    "        author_url  = f'https://ww3.lectulandia.com/autor/{author_name}'\n",
    "        return author_url\n",
    "\n",
    "\n",
    "    def get_books_titles_from_author_url(self, author_url):\n",
    "        self.browser.open(author_url)\n",
    "        books_titles_from_author = [\n",
    "            f\"{book['title']}\"\n",
    "            for book in self.browser.find_all(\"a\", class_=\"title\")]\n",
    "        print(f'Number of titles retrieved: {len(books_titles_from_author)}')\n",
    "        return books_titles_from_author\n",
    "\n",
    "\n",
    "    def get_urls_from_author_url(self, author_url, urls_from_author=None):\n",
    "        # TODO: recopilar TODAS las paginas, no solo la primera\n",
    "        if urls_from_author is None:\n",
    "            urls_from_author = []\n",
    "\n",
    "        self.browser.open(author_url)\n",
    "        new_urls = [\n",
    "            f\"https://ww3.lectulandia.com{book['href']}\"\n",
    "            for book in self.browser.find_all(\"a\", class_=\"card-click-target\")]\n",
    "        urls_from_author.extend(new_urls)\n",
    "\n",
    "        next_page_link = self.browser.find(\"a\", class_=\"next page-numbers\")\n",
    "        if next_page_link:\n",
    "            next_page_url = f\"https://ww3.lectulandia.com{next_page_link['href']}\"\n",
    "            self.get_urls_from_author_url(next_page_url, urls_from_author)\n",
    "            #next_page_urls = self.get_urls_from_author_url(next_page_url)  # Recursive call\n",
    "\n",
    "        return urls_from_author\n",
    "\n",
    "\n",
    "    def get_download_link(self, book_url):\n",
    "        self.browser.open(book_url)\n",
    "        for link in self.browser.find_all(\"a\"):\n",
    "            if \"download.php?t=1\" in str(link):\n",
    "                return f\"https://www.lectulandia.com{link['href']}\"\n",
    "\n",
    "\n",
    "    def get_batch_download_links(self, urls_from_author):\n",
    "        download_links = [self.get_download_link(book_url) for book_url in urls_from_author]\n",
    "        return download_links\n",
    "\n",
    "\n",
    "    def download_book(self, download_url, author):\n",
    "        # Replace with library folder\n",
    "        library_folder = \"F:\\Calibre Library\"\n",
    "        author_folder  = os.path.join(library_folder, author)\n",
    "        if not os.path.exists(author_folder):\n",
    "            os.makedirs(author_folder)\n",
    "\n",
    "        print(f'Downloading book from {download_url}')\n",
    "        self.browser.open(download_url)\n",
    "        pattern = re.compile(\"var linkCode = \\\"(.*?)\\\";\")\n",
    "        section = pattern.findall(str(self.browser.parsed))\n",
    "        ant_url = f'https://www.antupload.com/file/{section[0]}'\n",
    "        self.browser.open(ant_url)\n",
    "\n",
    "        try:\n",
    "            filename = self.browser.find(\n",
    "                \"div\", id=\"fileDescription\").find_all(\"p\")[1].text.replace(\n",
    "                    \"Name: \", \"\")\n",
    "            print(filename)\n",
    "            size = self.browser.find(\n",
    "                \"div\", id=\"fileDescription\").find_all(\"p\")[2].text\n",
    "            file_url = self.browser.find(\"a\", id=\"downloadB\")\n",
    "            print(size)\n",
    "            time.sleep(2)\n",
    "            self.browser.follow_link(file_url)\n",
    "            file_path = os.path.join(author_folder, filename)\n",
    "            if not os.path.exists(file_path):\n",
    "                with open(file_path, \"wb\") as epub_file:\n",
    "                    epub_file.write(self.browser.response.content)\n",
    "                    print(f'File has been saved: {epub_file.name}')\n",
    "                return filename, size\n",
    "            else:\n",
    "                print(f'File already exists: {file_path}')\n",
    "                return None\n",
    "        except:\n",
    "            print(self.browser.parsed)\n",
    "\n",
    "\n",
    "    def batch_download_books(self, urls_from_author, author):\n",
    "        for url in urls_from_author:\n",
    "            self.download_book(url, author)\n",
    "            #time.sleep(1)\n",
    "\n",
    "\n",
    "    def get_book_page_list(self, page:int):\n",
    "        self.browser.open(f'https://ww3.lectulandia.com/book/page/{page}/')\n",
    "        return [\n",
    "            f\"https://ww3.lectulandia.com{book['href']}\"\n",
    "            for book in self.browser.find_all(\"a\", class_=\"card-click-target\")\n",
    "        ]\n",
    "\n",
    "\n",
    "    def download_full_page(self, page:int):\n",
    "        print(f\"Downloading page: {page} \")\n",
    "        books = self.get_book_page_list(page)\n",
    "        for book in books:\n",
    "            time.sleep(1)\n",
    "            download_url = self.get_download_link(book)\n",
    "            print(f\"Worker: {self.worker_num} on page: {page}\", self.download_book(download_url))\n",
    "\n",
    "\n",
    "class Worker(Thread):\n",
    "    def __init__(self, queue, worker_number, proxy=None):\n",
    "        Thread.__init__(self)\n",
    "        self.queue      = queue\n",
    "        self.downloader = Downloader(proxy)\n",
    "        self.wrk_num    = worker_number\n",
    "\n",
    "    def run(self):\n",
    "        while True:\n",
    "            page = self.queue.get()\n",
    "            try:\n",
    "                print(f\"Worker: {self.wrk_num} downloading page: {page}\")\n",
    "                self.downloader.download_full_page(page)\n",
    "            finally:\n",
    "                self.queue.task_done()\n",
    "\n",
    "\n",
    "def main():\n",
    "    pages   = [x + 1 for x in range(8)]\n",
    "    proxies = None #[None, \"https://188.168.75.254:56899\"]\n",
    "    queue   = Queue()\n",
    "    for x in range(2):\n",
    "        worker = Worker(queue, x, proxies[x])\n",
    "        worker.daemon = True\n",
    "        worker.start()\n",
    "\n",
    "    for page in pages:\n",
    "        queue.put(page)\n",
    "\n",
    "    queue.join()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate Downloader class\n",
    "test = Downloader(worker_num=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select desired author\n",
    "author        = \"arthur conan doyle\"\n",
    "parsed_author = unidecode(author.title())\n",
    "\n",
    "author_url       = test.get_author_url(author)\n",
    "urls_from_author = test.get_urls_from_author_url(author_url)\n",
    "#downloaded_link  = test.get_download_link(urls_from_author[0])\n",
    "downloaded_links = test.get_batch_download_links(urls_from_author)\n",
    "\n",
    "# Download books from batch of links\n",
    "test.batch_download_books(downloaded_links, author=parsed_author)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "scrapper_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
